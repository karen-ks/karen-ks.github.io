<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Karen Singh - Portfolio</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="../../assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="../../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="../../assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="../../assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../../assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v3.7.0
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <a href="../../index.html"><img src="../../assets/img/profile-img.jpg" alt="" class="img-fluid rounded-circle"></a>
        <h1 class="text-light"><a href="../../index.html">Karen Singh</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="mailto:work.karen8@outlook.com" class="email" target="_blank"><i class="bx bxs-envelope"></i></a>
          <a href="https://www.linkedin.com/in/karen-kaur-premajit-singh/" class="linkedin" target="_blank"><i class="bx bxl-linkedin"></i></a>
          <a href="https://twitter.com/karen_ks8" class="twitter" target="_blank"><i class="bx bxl-twitter"></i></a>
          <a href="https://github.com/karen-ks" class="github" target="_blank"><i class="bx bxl-github"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="../../index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i><span>About</span></a></li>
<!-- DROPDOWN MENU END -->
          <li><a href="../../index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="../../index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
        </ul>
      </nav>
<!-- .nav-menu -->
    </div>

    <div class="row">
      <div class="col-lg-12 d-flex justify-content-center">
          <a href="https://www.credly.com/badges/c6a21456-6569-4cce-b8a8-1d7faac5c86b/public_url" target="_blank"><img src="../../assets/img/microsoft-certified-azure-ai-fundamentals.png" alt="Microsoft Certified Azure AI Fundamentals"></a>
          <a href="https://www.credly.com/badges/c38088fb-d04b-4101-a065-68aa3845cd01/public_url" target="_blank"><img src="../../assets/img/microsoft-certified-azure-data-fundamentals.png" alt="Microsoft Certified Azure Data Fundamentals"></a>
      </div>
    </div>

  </header>
<!-- End Header -->

  <main id="main">

    <!-- Page Header-->
    <header class="masthead" >
        <div class="container position-relative px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-10 col-lg-8 col-xl-7">
                    <div class="post-heading">
                        <h1>Explainable Artificial Intelligence in Bias Mitigation</h1>
                        <h2 class="subheading"><em>An application of Explainable Artificial Intelligence to identify potential bias in datasets.</em></h2>
                        <span class="meta">
                            11 May 2022
                        </span>
                        <br><br>
                        <div class="link-download">
                          <h5><a href="../XAI_biasmit.pdf" target="_blank" download><i class="bx bxs-download"></i> Complete PDF</a></h5>
                          <h5><a href="https://github.com/karen-ks/masters-project" target="_blank" download><i class="bx bxl-github"></i> Github Repo</a></h5>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </header>
    <!-- End Header -->

    <!-- Post Content-->
    <article class="mb-4">
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-10 col-lg-8 col-xl-7">

                    <h2 class="section-heading">Abstract</h2>
                    <p>Fairness in machine learning is growing in attention where recent methods have addressed the discrimination between particular demographic groups that contain attributes classified as sensitive that include age, gender and race. Studies have also shown if the dataset itself is biased, it can lead to unfair decision making when used in training models.</p>
                    <p>In this paper, I propose a framework combining a number of classification algorithms, fairness metrics and feature explainability methods to highlight and potentially address bias generation resulting from the training data.</p>

                    <h2 class="section-heading">Research Purpose</h2>
                    <p>This report aims at casting light on the problem of model transparency and propose a frameowrk addressing the main challenge of a dataset:</p>
                    <blockquote class="blockquote">How do individual training data entries influence biased and inaccurate results?</blockquote>
                    <blockquote class="blockquote">How can identifying biased entries be used to improve representation in the datasets to improve both fairness and accuracy?</blockquote>

                    <p><b><i>Aim</b></i></p>
                    <p>Identifying and promoting the fairness of AI applications and machine learning techniques in the industry.</p>

                    <p><b><i>Objectives</b></i></p>
                    <li>Highlight how existing technologies influence how bias is identified in the dataset - either using evaluation metrics or bias quantifiers.</li>
                    <li>Proposing a framework to identify bias in datasets using a combination of fairness and bias quantifiers alongside existing machine learning models.</li>
                    <li>Proposing a method to produce the relationship between the input and output to identify data entries influencing inaccurate or biased results</li>
                    <p>This report achieved the first two objectives but where the third objective was not met, this will be proposed as future work to be future work to be pursued.</p>

                    <h2 class="section-heading">Methodology</h2>
                    <p>Two binary classification datasets were used in this paper - <a href="https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset" target="_blank">Credit Card Default</a> and <a href="https://www.kaggle.com/c/1056lab-diabetes-readmission-prediction" target="_blank">Diabetes Readmission</a>. Each of the two datasets contains at least one identified protected attribute that could influence the outcome of a prediction.</p>
                    <img class="img-fluid" src="../../assets/img/portfolio/xai_biasmit1.png" alt="ROC curves for the logistic credit risk model and XGBoost model">
                    <br>
                    <p>A number of performance indicators were used in this paper to measure the model's behaviour. They include the ROC (Receiver Operating Characteristic) Curves, AUC (Area under the ROC Curve), Accuracy, Precision, F1-Score and Specificity. Two fairness metrics - FairML and LIME - were selected to analyse any undesired bias in the training data / model.</p>
                    <p>Two classification models were used in this study - Random Forest and LightGBM. RandomizedSearchCV and GridSearchCV were used to carry out hyperparameter tuning.</p>

                    <h2 class="section-heading">Results</h2>
                    <p>The results as an entirety did not indicate that the designated sensitive attributes play a major role in the model's results although it cannot be concluded as such. The performance metrics were not at it's peak performance as a result of an attempt of preserving the integrity of the original dataset as best possible.</p>

                    <h2 class="section-heading">Conclusion</h2>
                    <p>Although there was insufficient evidence to prove that there was significant bias in the dataset, the feature importance of the Diabetes Readmission dataset using the LightGBM model did indicate that the designated sensitve attribute (race) was a major influence on the model's output. This paper does not conclude that it is sufficient to rule out the possibility of sensitive attributes influencing the model's output and hence, the presence of bias.</p>
                    <p>This paper also argues that accuracy should not be the only performance indiciator of a model, the performance metrics were not adapted to preserve the integrity of the original dataset as much as possible to create a baseline indicater of model performance to perform bias quantification in the future.</p>
                    <p>Tjos paper as a whole addressess the legality, ethics and professionalism of the use of AI applications in the industry. The provision, utilisation and management of an automated decision-making system may be legal and professional in the industry but the key issue being addressed and is aimed at resolving is raising the awareness of the ethics of how those systems manage the data flowing through it.</p>

                    <h2 class="section-heading">Future Work</h2>
                    <p>This paper proposes the involvement of technical expertise to interpret the results of the LIME model's outputs to aggregate local input's feature importance to identify specific entries that are influencing the overall model's performance. The future aim for the aggregate quantification for individual inputs would be to identify how sensitive or protected attributes contribute to the over or under-representation in the dataset and hence, be able to improve the training dataset.</p>

                </div>
            </div>
        </div>
    </article>

  </main><!-- End #main -->





  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <span>2022 by Karen Singh</span>
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="../../assets/vendor/purecounter/purecounter.js"></script>
  <script src="../../assets/vendor/aos/aos.js"></script>
  <script src="../../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="../../assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="../../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="../../assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="../../assets/vendor/typed.js/typed.min.js"></script>
  <script src="../../assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="../../assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="../../assets/js/main.js"></script>

</body>

</html>
