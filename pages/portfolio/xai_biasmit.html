<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Karen Singh - Portfolio</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="../../assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../../assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="../../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="../../assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="../../assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../../assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v3.7.0
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <a href="index.html"><img src="../../assets/img/profile-img.jpg" alt="" class="img-fluid rounded-circle"></a>
        <h1 class="text-light"><a href="index.html">Karen Singh</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="mailto:work.karen8@outlook.com" class="email" target="_blank"><i class="bx bxs-envelope"></i></a>
          <a href="https://www.linkedin.com/in/karen-kaur-premajit-singh/" class="linkedin" target="_blank"><i class="bx bxl-linkedin"></i></a>
          <a href="https://twitter.com/karen_ks8" class="twitter" target="_blank"><i class="bx bxl-twitter"></i></a>
          <a href="https://github.com/karen-ks" class="github" target="_blank"><i class="bx bxl-github"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="../../index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i><span>About</span></a></li>
<!-- DROPDOWN MENU END -->
          <li><a href="../../index.html#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="../../index.html#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
        </ul>
      </nav>
<!-- .nav-menu -->
    </div>

    <div class="row">
      <div class="col-lg-12 d-flex justify-content-center">
          <a href="https://www.credly.com/badges/c6a21456-6569-4cce-b8a8-1d7faac5c86b/public_url" target="_blank"><img src="../../assets/img/microsoft-certified-azure-ai-fundamentals.png" alt="Microsoft Certified Azure AI Fundamentals"></a>
          <a href="https://www.credly.com/badges/c38088fb-d04b-4101-a065-68aa3845cd01/public_url" target="_blank"><img src="../../assets/img/microsoft-certified-azure-data-fundamentals.png" alt="Microsoft Certified Azure Data Fundamentals"></a>
      </div>
    </div>

  </header>
<!-- End Header -->

  <main id="main">

    <!-- Page Header-->
    <header class="masthead" >
        <div class="container position-relative px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-10 col-lg-8 col-xl-7">
                    <div class="post-heading">
                        <h1>Explainable Artificial Intelligence in the Transparency of Credit Risk Management: A Mixed Method Research</h1>
                        <h2 class="subheading"><em>An application of Explainable Artificial Intelligence to encourage transparency of existing Black-Box Models .</em></h2>
                        <span class="meta">
                            11 May 2021
                        </span>
                        <br><br>
                        <!--<a href="../../pages/XAI_transprency_creditriskmgt.pdf" target="blank" ><i class="bx bxs-file-pdf"></i></a> -->
                        <div class="link-download">
                          <h5><a href="../XAI_transprency_creditriskmgt.pdf" target="_blank" download><i class="bx bxs-download"></i> Complete PDF</a></h5>
                          <h5><a href="https://github.com/karen-ks/AI-ethics" target="_blank" download><i class="bx bxl-github"></i> Github Repo</a></h5>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </header>
    <!-- End Header -->

    <!-- Post Content-->
    <article class="mb-4">
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-10 col-lg-8 col-xl-7">
                  
                    <h2 class="section-heading">Abstract</h2>
                    <p>As we leap into the dawning digital revolution, the implementation of Artificial Intelligence across various industries is increasing at as fast a pace as is the formation of data. However, as we progress towards the ethical management of said data, we find ourselves facing a limitation of the use of AI-based systems: transparency. The nature of previous and current machine learning models are black-box based which limits our access to understanding how these models arrive to their results. Thus, both providers and consumers are blindisghted as to how the data garnered weighs into said results.</p>
                    <p>This is where the discussion of Explainable Artificial Intelligence emerges that promises an increase in the trust and transparency of Artificial Intelligence systems. Trust is key to building confidence and acceptence of Artificial Intelligence-based decision-making systems regardless of the industry it is implemented in. This study explores a survey on Explainable Artificial Intelligence to understand how it promotes transparency and will be followed by a replicaton of an empirical analysis of SMEs requesting peer-to-peer lending using an Explainable Artifiical Intelligence model to understand how their financial characteristics can be used to predict future behaviour.</p>

                    <h2 class="section-heading">Research Purpose</h2>
                    <p>This mixed method research is based on a written paper by <a href="https://www.frontiersin.org/articles/10.3389/frai.2020.00026/full" target="_blank">Bussmann et al (2020)</a> to raise the key research question:</p>
                    <blockquote class="blockquote">How can transparency be encouraged using Explainable AI in credit risk management?</blockquote>
                    <p>This study uses a mixed methods research methodology and attempts to conduct parallel quantitative and qualitative research. The above research question is broken down into the following individual specific research questions that include quantitative and qualitative sub-questions that will be integrated back to the main research question.</p>
                    <p>The first sub-question below is to be addressed using the qualitative component of the study.</p>
                    <p><b><i>RQ1: How does Explainable Artificial Intelligence increase transparency?</p></b></i>
                    <p>The component of the study utilises an existing publication on a <a href="https://ieeexplore.ieee.org/document/8466590" target="_blank">survey on Explainable AI</a>. By answering this research question, the qualitative study seeks to explore how Explainable AI has been utilised to promote transparency.</p>
                    <p>The second sub-question is to be answered by the quantitative component of this study, specified as below.</p>
                    <p><b><i>RQ2: How can Explainable Artificial Intelligence be used to implement the transparency of decision making within peer-to-peer lending?</p></b></i>
                    <p>As this study uses a mixed methods research, the quantitative and qualitative components should be connected with each other rather than be studied separately. The connection between the quantitative and qualitative studies begins at the research design - the construction of the research questions.</p>

                    <h2 class="section-heading">Analysis Approach</h2>
                    <p><b><i>Qualitative Analysis</b></i></p>
                    <p>This study refers to a <a href="https://ieeexplore.ieee.org/document/8466590" target="_blank">survey on Explainable AI by Adadi, A et al. (2018)</a> to answer the qualitative research question of how Explainable AI promotes transparency.</p>
                    <p><b><i>Quantitative Analysis</b></i></p>
                    <p>The data considered was sourced from a study by <a href="https://www.tandfonline.com/doi/full/10.1080/08982112.2019.1655159" target="_blank">Guidici, P. et al</a> that was initially supplied by the European External Credit Assessment Institution (ECAI). They specialise in credit scoring for peer-to-peer lending platforms focused on SME commercial lending. The dataset is made up of official financial information on 4,514 Italian SMEs that represent the target of peer-to-peer lending platforms. The information about the status where 0 = active and 1 = defaulted are also included. The dataset shows 11.03% of the firms have defaulted.</p>
                    <p>The study aims to recreate the XGBoost model that was proposed by Bussmann et al (2020) that was able to increase the performance of the prediction of an existing logistic regression scoring model constructed by <a href="https://econpapers.repec.org/article/eeestapro/v_3a136_3ay_3a2018_3ai_3ac_3ap_3a160-164.htm" target"_blank">Giudici (2018)</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0378437119301372" target="_blank">Ahelegby et al. (2019)</a>, and <a href="https://www.frontiersin.org/articles/10.3389/frai.2019.00003/full" target="_blank">Giudici et al.(2019)</a>. The results from the model will then be explained by employing Shapley values.</p>
                    <p>The combination of both the qualitative and quantitative analysis will be used to show how the application of Explainable Artificial Intelligence can increase the transparency of decision making models.</p>

                    <h2 class="section-heading">Results & Discussion</h2>
                    <p>Python was used for this study. The dataset from the ECAI was split into a training set of 80& and a test set of 20%. A logistic regression model was first estimated on the training set then applied to the test set. This was used as a basis for comparison with the gradient boosting model XGBoost. The XGBoost model was then also estimated on the training set to be applied to the test set. The ROC curves of the two models are as follows:</p>
                    <img class="img-fluid" src="../../assets/img/portfolio/xai_transparency_creditriskmgt1.png" alt="ROC curves for the logistic credit risk model and XGBoost model">
                    <br>
                    <!-- <p><span class="caption text-muted">Receiver Operating Characteristic (ROC) curves for the logistic credit risk model and for the XGBoost model. The results relating to the XGBoost model is shown in blue and the logistic model's results is in orange.</span></p> -->
                    <p>Note that the XGBoost improves the predictive accuracy in comparison to the logistic regression model, where the graph indicates an increase from 0.54 to 0.66. Shapley values were calculated for four randomly selected firms in the data set to indicate which variables contributed towards the predictions of whether or not that firm would default.</p>
                    <p>The XGBoost model combined with the interpretation of results by Shapley values is a suitable alternative with respect to the lack of transparency in black-box decision-making models. The concept of black-box model that have been exploited by technological companies in order to protect their intellectual property to conserve competitiveness. This contradicts the need for responsible AI whose three pillars are accountability, responsiblity and transparency.</p>
                    <p>Tje use of XAI systems generally requires justifications for a particular outcome, especially in cases where unexpected decisions are made. This allows for auditable ways to support algorithmic decisions to encourage fair and ethical decisions that will build trust. In addition to justifying a decision, there is also a deeper understanding to unknown vulnerabilities that can assist debugging.</p>
                    <p>As discussed in the survey by Adadi (2018), AI tools in the financial services poses queries around fair lending despite the fact that the financial indsutry is heavily regulated and are responsible for making fair decisions. XAI implementation provides an outlet to provide explanations around credit application decisions.</p>
                    <p>The image below shows the contribution of each explanatory variable according to the Shapley's decomposition for four predictions, two of which have defaulted and the others have not. The red bars are an indication of low variable importance and the blue bars indicidate a high variable importance.</p>
                    <img class="img-fluid" src="../../assets/img/portfolio/xai_transparency_creditriskmgt2.png" alt="ROC curves for the logistic credit risk model and XGBoost model">
                    <br>

                    <h2 class="section-heading">Conclusion</h2>
                    <p>The replication of the study by Bussman et al (2020) shows that the use of Explainable Artificial Intelligence, in this case the XGBoost model alongside interpretation by Shapley values, reaffirms that the use of Explainable AI can indeed increase transparency in decision making models. This meet the current need for high predictive accuracy alongside high interpretability in this era of transparent data management.</p>
                    <p>Future studies would propose to explore alternative algorithms that can further improve predicitive accuracy whilst maintaining or even improving the model interpretability. As also proposed by Bussmann et al. (2020), an alternative would also be to improve model development by utilising the Shapley values to identify key features that can improve model predictions. Stricter implementation of legal responsibilities should also be put in place and monitored. This responsibility lies within the organisations utilising the data for their decision making systems. Relating this to the current EU GDPR regulations, it remains to be quite general with respect to the Artificial Intelligence systems. More research should be carried out to explore possible technical and theoretical checks to be put in place to regulate the ethical use of data within decision making.</p>

                </div>
            </div>
        </div>
    </article>

  </main><!-- End #main -->





  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>iPortfolio</span></strong>
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="../../assets/vendor/purecounter/purecounter.js"></script>
  <script src="../../assets/vendor/aos/aos.js"></script>
  <script src="../../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="../../assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="../../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="../../assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="../../assets/vendor/typed.js/typed.min.js"></script>
  <script src="../../assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="../../assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="../../assets/js/main.js"></script>

</body>

</html>
